---
title: "BST 270 In-class Project"
output: html_document
---

## Introduction
In this Rmarkdown file we will attempt to reproduce the figures, tables and analyses presented in the paper [_Relation between Optimism and Lipids in Midlife_.](https://www.ajconline.org/article/S0002-9149(13)00388-3/pdf)

1. Boehm, J. K., Williams, D. R., Rimm, E. B., Ryff, C., & Kubzansky, L. D. (2013). Relation between Optimism and Lipids in Midlife. The American Journal of Cardiology, 111(10), 1425-1431.
http://doi.org/10.1016/j.amjcard.2013.01.292

In 1995, MIDUS survey data were collected from a total of 7,108 participants. The baseline sample was comprised of individuals from four subsamples: (1) a national RDD (random digit dialing) sample ($n = 3,487$); (2) oversamples from five metropolitan areas in the U.S. ($n = 757$); (3) siblings of individuals from the RDD sample ($n = 950$); and (4) a national RDD sample of twin pairs ($n = 1,914$). All eligible participants were non-institutionalized, English-speaking adults in the contiguous United States, aged 25 to 74. All respondents were invited to participate in a phone interview of approximately 30 minutes in length and complete 2 self-administered questionnaires (SAQs), each of approximately 45 pages in length. In addition, the twin subsample was administered a short screener to assess zygosity and other twin-specific information. With funding provided by the National Institute on Aging, a longitudinal follow-up of MIDUS I began in 2004. Every attempt was made to contact all original respondents and invite them to participate in a second wave of data collection. Of the 7,108 participants in MIDUS I, 4,963 were successfully contacted to participate in another phone interview of about 30 minutes in length. MIDUS II also included two self-administered questionnaires (SAQs), each of about 55 pages in length, which were mailed to participants. The overall response rate for the SAQs was 81\%. Over 1,000 journal articles have been written using MIDUS I and II data since 1995.

Here we attempt to reproduce the findings of [1] and critique the reproducibility of the article. This particular article focuses only on MIDUS II data, including biomarker data, and investigates the relationship between optimism and lipids. The MIDUS II data and supporting codebook and other documents can be downloaded \href{https://www.icpsr.umich.edu/icpsrweb/ICPSR/studies/4652?archive=ICPSR&q=MIDUS+}{here}. The data can be downloaded in multiple formats. Here we use the R data files and perform all data cleaning and analyses in R version 3.5.1. The biomarker data can be downloaded \href{https://www.icpsr.umich.edu/icpsrweb/NACDA/studies/29282}{here}.


## Data Dictionary
This manuscript uses several variables from multiple data files. Some of these variables don't have intuitive names and need to be manually looked up either online or in the codebooks provided in the data downloads. [This google sheet](https://docs.google.com/spreadsheets/d/1W9LxvfuGnVJm4tST61RtBPJYHuHzjuZE6lUKsIwtHaU/edit?usp=sharing) acts as a data dictionary for only the variables we believe were used for the analysis according to our understanding of the methods section of the paper.

## Load needed packages
```{r, message=FALSE, warning=FALSE}
library(dplyr)
library(ggplot2)
library(tidyverse)
library(arsenal)
library(kableExtra)
```


## Load and combine data
```{r}
load("ICPSR_04652/DS0001/04652-0001-Data.rda") # load MIDUS2 interview/questionnaire data
load("ICPSR_29282/DS0001/29282-0001-Data.rda") # load MIDUS2 biomarker data
df <- inner_join(da29282.0001, da04652.0001, by="M2ID") # merge the two dataframes using an inner join
dim(df)
```
We have a total of 1,054 participants after merging the data frames. 

### Optimism Score
We can drop any observation with a missing value in the `B1SORIEN` column which indicates the overall optimism score for a given participant.

```{r}
df <- df %>% drop_na(B1SORIEN) # drop rows with missing optimism values 
dim(df)
```
We lose 4 participants.

### Lipid Measurments Filter

Next, we drop the participants with missing lipid level measurements. The authors state that they are considering "a lipid panel of total cholesterol, HDL cholesterol, LDL cholesterol, and triglycerides". Therefore, we can drop rows with missing values in the `B4BCHOL` (total cholesterol), `B4BLDL` (LDL cholesterol), `B4BHDL` (HDL cholesterol), and `B4BTRIGL` (triglycerides) columns.

```{r}
df <- df %>% drop_na(B4BCHOL, B4BLDL, B4BHDL, B4BTRIGL) # drop rows with missing lipid measurements
dim(df)
```
We lose 11 participants. 

### Potential Confounders Filter

Next, we drop observations with missing confounder variables, which according to the authors were "factors known to be associated with the lipid profiles". These include "age (in years), gender, race (white, nonwhite), education (less than high school degree, high school degree, some college, college degree or greater), household income, and months between the optimism and serum lipid assessments". All of these are easily identified, except for months between optimisim and serum lipid assessments. There are two potential variables that could fit this description, `B4ZB1PLG` and `B4ZB1SLG`. They measure the lag (in months) between the phone interview and the self-administered questionnaire, respectively, and the biomarker assessment. It is unclear whether optimism was assessed during the phone interview or with the questionnaire, but we will assume the latter and use `B4ZB1SLG`. Additionally, the authors wish to consider certain health statuses as confounders, including, chronic conditions (none or $\geq 1$ condition) and blood pressure medication use (no, yes). The chronic conditions variable is easily identified as `B1SCHROX`, but there are several columns for blood pressure medication, including `B1PA24B`, `B1PA24C`, `B1PA24D`, and `B4XPC_1156`. Using any of these variables for our filter leads to less than 990 participants. This may be because those without high blood pressure did not answer a question about whether or not they used medication to control "their" high blood pressure, thus leading to a lot of missing values. This appears to be the case when consulting the data cookbooks as well, so we will have to recode NAs to 0 if they don't have high blood pressure (found in `B1PA24`). We choose to use `B1PA24B` as our blood pressure indicator as well, as it has the least missing values. In order to examine optimismâ€™s independent effects from psychological ill-being, negative affect was also controlled for in the secondary analyses. Negative affect was assessed during the psychosocial project using 5 items from a widely used and psychometrically valid scale, and is found in the `B1SNEGAF` variable. 

```{r}
df <- df %>% drop_na(B1PA24) # drop rows with missing diagnosis of blood pressure

# fix blood pressure column as described above; if they answered no to ever being diagnosed with high blood pressure
# and have an NA for ever taking blood pressure medication, change NA to 0 (no).
df[is.na(df$B1PA24B),]$B1PA24B <- ifelse(df[is.na(df$B1PA24B),]$B1PA24 == "(2) NO", "(2) NO", NA)

# drop rows with missing potential confounders
df <- df %>% drop_na(B1PAGE_M2.x, B1PRSEX.x, B1PF7A, B1PB1, B1STINC1, B4ZB1SLG, B1SCHROX, B1PA24B, B1SNEGAF) 

dim(df)
```
We lose 28 participants.

### Pathway Variables Filter

Lastly, the authors wish to control for "potential behavioral pathways", including "smoking status
(current smoker, past smoker, never smoker), average number of drinks consumed/day in the past month, regular exercise $\geq 3$ times/week for 20 minutes (no, yes), and prudent diet". We can find out it someone has ever smoked using the `B4H26` column and we can use `B4H26A` to find out if they currently smoke. We can use `B4H36` as an indicator for average number of drinks consumed/day in the past month, but it drops our cohort size well below 990. This appears to be a similar issue that we ran into with blood pressure in that a lot of missing values appear to be because a participant did not drink at all in the past month. We will use the `B4H33` column to check whether a patient has had anything to drink in the past month, and if they still have a missing value, then we will drop that participant. We can use `B4H25` for the exercise variable. According to the authors, "a prudent diet score was calculated by giving the participants a point for consuming $\geq 3$ servings/day of fruit and vegetables, $\geq 3$ servings/day of whole grains, $\geq 1$ servings/week of fish, $\geq 1$ servings/week of lean meat, no sugared beverages, $\leq 2$ servings/week of beef or high-fat meat, and food at a fast food restaurant less than once per week." We will have to hand calculate this value ourselves, and drop all participants with a missing value for a given variable. Lastly, the authors also use BMI measured at biomarker assesment as a pathway variable (`B4PBMI`).

```{r}
# calculate prudent diet score
df <- df %>% mutate(veggies    = ifelse(B4H21 == "(3) 3-4 SERVINGS/DAY" | B4H21 == "(4) 5 OR MORE SERVINGS/DAY", 1, 0),
                    grains     = ifelse(B4H22 == "(3) 3-4 SERVINGS/DAY" | B4H22 == "(4) 5 OR MORE SERVINGS/DAY", 1, 0),
                    fish       = ifelse(B4H23A == "(3) 1-2 X/WEEK" | B4H23A == "(4) 3-4 X/WEEK" | 
                                        B4H23A == "(5) 5 OR MORE X/WEEK", 1, 0),
                    lean_meat  = ifelse(B4H23C == "(3) 1-2 X/WEEK" | B4H23C == "(4) 3-4 X/WEEK" | 
                                        B4H23C == "(5) 5 OR MORE X/WEEK", 1, 0),
                    beef       = ifelse(B4H23B == "(3) 1-2 X/WEEK" | B4H23B == "(2) LESS THAN ONCE/WEEK" | 
                                        B4H23B == "(1) NEVER", 1, 0),
                    restaurant = ifelse(B4H24 == "(2) LESS THAN ONCE/WEEK" | B4H24 == "(1) NEVER", 1, 0),
                    sugarbev   = ifelse(B4H20 == "(1) NONE", 1, 0),
                    prudent_diet = veggies + grains + fish + lean_meat + beef + restaurant + sugarbev)


# fix number of drinks column
df[is.na(df$B4H36),]$B4H36 <- ifelse(df[is.na(df$B4H36),]$B4H33=="(2) NO", 0, NA)

 # drop rows with missing pathways variables
df <- df %>% drop_na(B4H26, B4H25, B4H36, prudent_diet, B4PBMI)

dim(df)
```

```{r}
# keep the variables we need for the figure and tables
df <- df %>% dplyr::select(M2ID, B1SORIEN, B4BCHOL, B4BLDL, B4BHDL, B4BTRIGL, B1PAGE_M2.x, 
                    B1PRSEX.x, B1PF7A, B1PB1, B1STINC1, B4ZB1SLG, B1SCHROX, B1PA24B, 
                    B1SNEGAF, B4H26, B4H26A, B4H25, B4H36, prudent_diet, B4PBMI, B1SA12C, B4H1HD)

```

We lose another 9 individuals and have a sample of size 1,002. 

We were unable to achieve a sample size of $N = 990$ using our filters, so we do not have the exact same cohort from the original paper. We attempt to recreate Figure 1 and Tables 1-3 using our $N = 1,002$ observations instead. 

Note - we won't be calculating the column values or the p-values for Table 1.

## Figure 1

```{r}
df %>% mutate(opt_level = ifelse(B1SORIEN <= 22, "Low", ifelse(B1SORIEN <= 26, "Medium", "High")),
              B1SORIEN = round(B1SORIEN)) %>%
  ggplot(aes(B1SORIEN)) +
  geom_histogram(binwidth = 0.5, col = "black", aes(fill = opt_level), bins = length(unique(df$B1SORIEN))) +
  scale_x_continuous(breaks = seq(6, 30, by = 2)) +
  scale_y_continuous(breaks = seq(0, 100, by=10)) +
  scale_fill_manual(values = c("white", "black", "gray")) +
  theme(legend.position = "none", text = element_text(size = 14),
        panel.grid.major.x = element_blank(), panel.grid.minor = element_blank()) +
  labs(y = "Frequency", x = "Optimisim Score")
```

## Table 1
```{r}
# Split participants into different levels of optimism groups
df <- df %>% mutate(level=ifelse(B1SORIEN <= 22, "Low", ifelse(B1SORIEN <= 26, "Medium", "High")))
n.Low <- (length(df$level[df$level == "Low"]))
n.Medium <- (length(df$level[df$level == "Medium"]))
n.High <- (length(df$level[df$level == "High"]))

# Calculate mean/sd of age within each group
mean.age.Low <- mean(df[df$level == "Low", ]$B1PAGE_M2.x)
sd.age.Low <- sd(df[df$level == "Low", ]$B1PAGE_M2.x)
mean.age.Medium <- mean(df[df$level == "Medium", ]$B1PAGE_M2.x)
sd.age.Medium <- sd(df[df$level == "Medium", ]$B1PAGE_M2.x)
mean.age.High <- mean(df[df$level == "High", ]$B1PAGE_M2.x)
sd.age.High <- sd(df[df$level == "High", ]$B1PAGE_M2.x)

# Calculate gender breakdown
n.males <- nrow(df[df$B1PRSEX.x == "(1) MALE", ])
n.females <- nrow(df[df$B1PRSEX.x == "(2) FEMALE", ])

row.percent.male.Low <- sum(df[df$B1PRSEX.x == "(1) MALE", ]$level == "Low") / n.males
row.percent.female.Low <- sum(df[df$B1PRSEX.x == "(2) FEMALE", ]$level == "Low") / n.females

row.percent.male.Medium <- sum(df[df$B1PRSEX.x == "(1) MALE", ]$level == "Medium") / n.males
row.percent.female.Medium <- sum(df[df$B1PRSEX.x == "(2) FEMALE", ]$level == "Medium") / n.females

row.percent.male.High <- sum(df[df$B1PRSEX.x == "(1) MALE", ]$level == "High") / n.males
row.percent.female.High <- sum(df[df$B1PRSEX.x == "(2) FEMALE", ]$level == "High") / n.females

# Calculate race breakdown
n.white <- nrow(df[df$B1PF7A == "(1) WHITE", ])
n.nonwhite <- nrow(df[df$B1PF7A != "(1) WHITE", ])

row.percent.white.Low <- sum(df[df$B1PF7A == "(1) WHITE", ]$level == "Low") / n.white
row.percent.nonwhite.Low <- sum(df[df$B1PF7A != "(1) WHITE", ]$level == "Low") / n.nonwhite

row.percent.white.Medium <- sum(df[df$B1PF7A == "(1) WHITE", ]$level == "Medium") / n.white
row.percent.nonwhite.Medium <- sum(df[df$B1PF7A != "(1) WHITE", ]$level == "Medium") / n.nonwhite

row.percent.white.High <- sum(df[df$B1PF7A == "(1) WHITE", ]$level == "High") / n.white
row.percent.nonwhite.High <- sum(df[df$B1PF7A != "(1) WHITE", ]$level == "High") / n.nonwhite
df$RACE_BINARY <- ifelse(df$B1PF7A == "(1) WHITE", "White", "Nonwhite")

# Calculate education breakdown
levels(df$B1PB1) <- list("(1) LESS THAN A HIGH SCHOOL DEGREE"=c("(01) NO SCHOOL/SOME GRADE SCHOOL (1-6)", 
                                                            "(02) EIGHTH GRADE/JUNIOR HIGH SCHOOL (7-8)", 
                                                            "(03) SOME HIGH SCHOOL (9-12 NO DIPLOMA/NO GED)"), 
                         "(2) HIGH SCHOOL DEGREE"=c("(04) GED", 
                                                    "(05) GRADUATED FROM HIGH SCHOOL"), 
                         "(3) SOME COLLEGE"=c("(06) 1 TO 2 YEARS OF COLLEGE, NO DEGREE YET", 
                                              "(07) 3 OR MORE YEARS OF COLLEGE, NO DEGREE YET"), 
                         "(4) COLLEGE DEGREE OR MORE"=c("(08) GRAD. FROM 2-YEAR COLLEGE, VOCATIONAL SCHOOL, OR ASSOC. DEGR", 
                                                        "(09) GRADUATED FROM A 4- OR 5-YEAR COLLEGE, OR BACHELOR'S DEGREE", 
                                                        "(10) SOME GRADUATE SCHOOL", 
                                                        "(11) MASTER'S DEGREE", 
                                                        "(12) PH.D., ED.D., MD, DDS, LLB, LLD, JD, OR OTHER PROFESS'NL DEG"))
n.1 <- nrow(df[df$B1PB1 == "(1) LESS THAN A HIGH SCHOOL DEGREE", ])
n.2 <- nrow(df[df$B1PB1 == "(2) HIGH SCHOOL DEGREE", ])
n.3 <- nrow(df[df$B1PB1 == "(3) SOME COLLEGE", ])
n.4 <- nrow(df[df$B1PB1 == "(4) COLLEGE DEGREE OR MORE", ])

row.percent.1.Low <- sum(df[df$B1PB1 == "(1) LESS THAN A HIGH SCHOOL DEGREE", ]$level == "Low") / n.1
row.percent.2.Low <- sum(df[df$B1PB1 == "(2) HIGH SCHOOL DEGREE", ]$level == "Low") / n.2
row.percent.3.Low <- sum(df[df$B1PB1 == "(3) SOME COLLEGE", ]$level == "Low") / n.3
row.percent.4.Low <- sum(df[df$B1PB1 == "(4) COLLEGE DEGREE OR MORE", ]$level == "Low") / n.4
col.percent.1.Medium <- sum(df[df$level == "Medium", ]$B1PB1 == "(1) LESS THAN A HIGH SCHOOL DEGREE") / n.Medium

row.percent.1.Medium <- sum(df[df$B1PB1 == "(1) LESS THAN A HIGH SCHOOL DEGREE", ]$level == "Medium") / n.1
row.percent.2.Medium <- sum(df[df$B1PB1 == "(2) HIGH SCHOOL DEGREE", ]$level == "Medium") / n.2
row.percent.3.Medium <- sum(df[df$B1PB1 == "(3) SOME COLLEGE", ]$level == "Medium") / n.3
row.percent.4.Medium <- sum(df[df$B1PB1 == "(4) COLLEGE DEGREE OR MORE", ]$level == "Medium") / n.4

row.percent.1.High <- sum(df[df$B1PB1 == "(1) LESS THAN A HIGH SCHOOL DEGREE", ]$level == "High") / n.1
row.percent.2.High <- sum(df[df$B1PB1 == "(2) HIGH SCHOOL DEGREE", ]$level == "High") / n.2
row.percent.3.High <- sum(df[df$B1PB1 == "(3) SOME COLLEGE", ]$level == "High") / n.3
row.percent.4.High <- sum(df[df$B1PB1 == "(4) COLLEGE DEGREE OR MORE", ]$level == "High") / n.4

# Calculate mean/sd of income within each group
mean.inc.Low <- mean(df[df$level == "Low", ]$B1STINC1)
sd.inc.Low <- sd(df[df$level == "Low", ]$B1STINC1)
mean.inc.Medium <- mean(df[df$level == "Medium", ]$B1STINC1)
sd.inc.Medium <- sd(df[df$level == "Medium", ]$B1STINC1)
mean.inc.High <- mean(df[df$level == "High", ]$B1STINC1)
sd.inc.High <- sd(df[df$level == "High", ]$B1STINC1)

# Calculate mean/sd of interval between assessment within each group
mean.int.Low <- mean(df[df$level == "Low", ]$B4ZB1SLG)
sd.int.Low <- sd(df[df$level == "Low", ]$B4ZB1SLG)
mean.int.Medium <- mean(df[df$level == "Medium", ]$B4ZB1SLG)
sd.int.Medium <- sd(df[df$level == "Medium", ]$B4ZB1SLG)
mean.int.High <- mean(df[df$level == "High", ]$B4ZB1SLG)
sd.int.High <- sd(df[df$level == "High", ]$B4ZB1SLG)

# Calculate chronic disease breakdown
n.yes <- nrow(df[df$B1SCHROX == "(1) YES", ])
n.no <- nrow(df[df$B1SCHROX == "(0) NO", ])

row.percent.yes.Low <- sum(df[df$B1SCHROX== "(1) YES", ]$level == "Low") / n.yes
row.percent.no.Low <- sum(df[df$B1SCHROX == "(0) NO", ]$level == "Low") / n.no

row.percent.yes.Medium <- sum(df[df$B1SCHROX== "(1) YES", ]$level == "Medium") / n.yes
row.percent.no.Medium <- sum(df[df$B1SCHROX == "(0) NO", ]$level == "Medium") / n.no

row.percent.yes.High <- sum(df[df$B1SCHROX== "(1) YES", ]$level == "High") / n.yes
row.percent.no.High <- sum(df[df$B1SCHROX == "(0) NO", ]$level == "High") / n.no

# Calculate blood pressure breakdown
n.yes <- nrow(df[df$B1PA24B == "(1) YES", ])
n.no <- nrow(df[df$B1PA24B == "(2) NO", ])

row.percent.yes.Low <- sum(df[df$B1PA24B== "(1) YES", ]$level == "Low") / n.yes
row.percent.no.Low <- sum(df[df$B1PA24B == "(2) NO", ]$level == "Low") / n.no

row.percent.yes.Medium <- sum(df[df$B1PA24B== "(1) YES", ]$level == "Medium") / n.yes
row.percent.no.Medium <- sum(df[df$B1PA24B == "(2) NO", ]$level == "Medium") / n.no

row.percent.yes.High <- sum(df[df$B1PA24B== "(1) YES", ]$level == "High") / n.yes
row.percent.no.High <- sum(df[df$B1PA24B == "(2) NO", ]$level == "High") / n.no

# Calculate mean/sd of BMI between assessment within each group
mean.bmi.Low <- mean(df[df$level == "Low", ]$B4PBMI)
sd.bmi.Low <- sd(df[df$level == "Low", ]$B4PBMI)
mean.bmi.Medium <- mean(df[df$level == "Medium", ]$B4PBMI)
sd.bmi.Medium <- sd(df[df$level == "Medium", ]$B4PBMI)
mean.bmi.High <- mean(df[df$level == "High", ]$B4PBMI)
sd.bmi.High <- sd(df[df$level == "High", ]$B4PBMI)

# Calculate smoking status breakdown
df$SMOKING_STATUS <- ifelse(df$B4H26 == "(2) NO", "Never", ifelse(df$B4H26A == "(1) YES", "Current", "Past"))
n.current <- nrow(df[df$SMOKING_STATUS == "Current", ])
n.past <- nrow(df[df$SMOKING_STATUS== "Past", ])
n.never <-  nrow(df[df$SMOKING_STATUS== "Never", ])

row.percent.current.Low <- sum(df[df$SMOKING_STATUS== "Current", ]$level == "Low", na.rm = T) / n.current
row.percent.past.Low <- sum(df[df$SMOKING_STATUS == "Past", ]$level == "Low", na.rm = T) / n.past
row.percent.never.Low <- sum(df[df$SMOKING_STATUS == "Never", ]$level == "Low", na.rm = T) / n.never

row.percent.current.Medium <- sum(df[df$SMOKING_STATUS== "Current", ]$level == "Medium", na.rm = T) / n.current
row.percent.past.Medium <- sum(df[df$SMOKING_STATUS == "Past", ]$level == "Medium", na.rm = T) / n.past
row.percent.never.Medium <- sum(df[df$SMOKING_STATUS == "Never", ]$level == "Medium", na.rm = T) / n.never

row.percent.current.High <- sum(df[df$SMOKING_STATUS== "Current", ]$level == "High", na.rm = T) / n.current
row.percent.past.High <- sum(df[df$SMOKING_STATUS == "Past", ]$level == "High", na.rm = T) / n.past
row.percent.never.High <- sum(df[df$SMOKING_STATUS == "Never", ]$level == "High", na.rm = T) / n.never

# Calculate mean/sd of alcohol consumption between assessment within each group
mean.alc.Low <- mean(df[df$level == "Low", ]$B4H36)
sd.alc.Low <- sd(df[df$level == "Low", ]$B4H36)
mean.alc.Medium <- mean(df[df$level == "Medium", ]$B4H36)
sd.alc.Medium <- sd(df[df$level == "Medium", ]$B4H36)
mean.alc.High <- mean(df[df$level == "High", ]$B4H36)
sd.alc.High <- sd(df[df$level == "High", ]$B4H36)

# Calculate mean/sd of prudent diet between assessment within each group
mean.diet.Low <- mean(df[df$level == "Low", ]$prudent_diet)
sd.diet.Low <- sd(df[df$level == "Low", ]$prudent_diet)
mean.diet.Medium <- mean(df[df$level == "Medium", ]$prudent_diet)
sd.diet.Medium <- sd(df[df$level == "Medium", ]$prudent_diet)
mean.diet.High <- mean(df[df$level == "High", ]$prudent_diet)
sd.diet.High <- sd(df[df$level == "High", ]$prudent_diet)

# Calculate exercise breakdown
n.yes <- nrow(df[df$B4H25 == "(1) YES", ])
n.no <- nrow(df[df$B4H25 == "(2) NO", ])

row.percent.yes.Low <- sum(df[df$B4H25== "(1) YES", ]$level == "Low") / n.yes
row.percent.no.Low <- sum(df[df$B4H25 == "(2) NO", ]$level == "Low") / n.no

row.percent.yes.Medium <- sum(df[df$B4H25== "(1) YES", ]$level == "Medium") / n.yes
row.percent.no.Medium <- sum(df[df$B4H25 == "(2) NO", ]$level == "Medium") / n.no

row.percent.yes.High <- sum(df[df$B4H25== "(1) YES", ]$level == "High") / n.yes
row.percent.no.High <- sum(df[df$B4H25 == "(2) NO", ]$level == "High") / n.no

# Calculate mean/sd of negative affect between assessment within each group
mean.neg.Low <- mean(df[df$level == "Low", ]$B1SNEGAF)
sd.neg.Low <- sd(df[df$level == "Low", ]$B1SNEGAF)
mean.neg.Medium <- mean(df[df$level == "Medium", ]$B1SNEGAF)
sd.neg.Medium <- sd(df[df$level == "Medium", ]$B1SNEGAF)
mean.neg.High <- mean(df[df$level == "High", ]$B1SNEGAF)
sd.neg.High <- sd(df[df$level == "High", ]$B1SNEGAF)

# Calculate mean/sd of total cholesterol between assessment within each group
mean.tot.Low <- mean(df[df$level == "Low", ]$B4BCHOL)
sd.tot.Low <- sd(df[df$level == "Low", ]$B4BCHOL)
mean.tot.Medium <- mean(df[df$level == "Medium", ]$B4BCHOL)
sd.tot.Medium <- sd(df[df$level == "Medium", ]$B4BCHOL)
mean.tot.High <- mean(df[df$level == "High", ]$B4BCHOL)
sd.tot.High <- sd(df[df$level == "High", ]$B4BCHOL)

# Calculate mean/sd of hdl cholesterol between assessment within each group
mean.hdl.Low <- mean(df[df$level == "Low", ]$B4BHDL)
sd.hdl.Low <- sd(df[df$level == "Low", ]$B4BHDL)
mean.hdl.Medium <- mean(df[df$level == "Medium", ]$B4BHDL)
sd.hdl.Medium <- sd(df[df$level == "Medium", ]$B4BHDL)
mean.hdl.High <- mean(df[df$level == "High", ]$B4BHDL)
sd.hdl.High <- sd(df[df$level == "High", ]$B4BHDL)

# Calculate mean/sd of ldl cholesterol between assessment within each group
mean.ldl.Low <- mean(df[df$level == "Low", ]$B4BLDL)
sd.ldl.Low <- sd(df[df$level == "Low", ]$B4BLDL)
mean.ldl.Medium <- mean(df[df$level == "Medium", ]$B4BLDL)
sd.ldl.Medium <- sd(df[df$level == "Medium", ]$B4BLDL)
mean.ldl.High <- mean(df[df$level == "High", ]$B4BLDL)
sd.ldl.High <- sd(df[df$level == "High", ]$B4BLDL)

# Calculate mean/sd of triglycerides between assessment within each group
mean.tri.Low <- mean(df[df$level == "Low", ]$B4BTRIGL)
sd.tri.Low <- sd(df[df$level == "Low", ]$B4BTRIGL)
mean.tri.Medium <- mean(df[df$level == "Medium", ]$B4BTRIGL)
sd.tri.Medium <- sd(df[df$level == "Medium", ]$B4BTRIGL)
mean.tri.High <- mean(df[df$level == "High", ]$B4BTRIGL)
sd.tri.High <- sd(df[df$level == "High", ]$B4BTRIGL)
```

For the most part, our table largely resembles Table 1 from the original paper. Obviously, given the different cohort sizes, we have some slight differences in certain values, but the same general trend seems to hold, and most of our values are very close to each other. However, there are some notable differences, which we enumerate here. 

1. There is a big discrepancy in our distribution of chronic conditions and the paper's reported chronic conditions distribution. The original paper had a p-value of 0.74, wheras we had a p-value of 0.001. There are a couple of reasons this discrepancy may have happened. The most probable, given that our other column values are fairly consistient, is that the authors use a different column to define their chronic conditions. However, it is unclear from the documentation which column would better describe chronic conditions then the one we used. Another possiblity is that the authors use a different version of the Midus II dataset, given that the paper was released in 2013 and the MIDUS II data website says the most recent version was published in 2017. This might also explain why we were unable to reach the same sample size.  

2. All of our blood pressure medication values are off by about 10% (we have about 10% less people using blood pressure medication). This might be because we did not accurately update the colum in the same way the authors did or we just used a different column then the authors. This is very likely given there were several different columns with this information and all of them were incomplete. 

3. Our alcohol consumption distribution across optimism levels is statistically significant at a 0.05 level, whereas this is not the case in the author's paper. However, the author's report a p-value of 0.06, so the small difference in our sample size likely explains the small difference that makes our distribution statistically significant. 

4. Our total cholesterol and LDL values are all approximately 10 mg/DL lower than the author's values. The most likely reason for this is that some sort of adjustment or correction was made to the cholesterol values in the more recent MIDUS II dataset as compared to the older version that was likely used by the authors. 

## Table 2
```{r}
# Encoding of variables as described in the paper
levels(df$B1PB1) <- list("(1) LESS THAN A HIGH SCHOOL DEGREE"=c("(01) NO SCHOOL/SOME GRADE SCHOOL (1-6)", 
                                                            "(02) EIGHTH GRADE/JUNIOR HIGH SCHOOL (7-8)", 
                                                            "(03) SOME HIGH SCHOOL (9-12 NO DIPLOMA/NO GED)"), 
                         "(2) HIGH SCHOOL DEGREE"=c("(04) GED", 
                                                    "(05) GRADUATED FROM HIGH SCHOOL"), 
                         "(3) SOME COLLEGE"=c("(06) 1 TO 2 YEARS OF COLLEGE, NO DEGREE YET", 
                                              "(07) 3 OR MORE YEARS OF COLLEGE, NO DEGREE YET"), 
                         "(4) COLLEGE DEGREE OR MORE"=c("(08) GRAD. FROM 2-YEAR COLLEGE, VOCATIONAL SCHOOL, OR ASSOC. DEGR", 
                                                        "(09) GRADUATED FROM A 4- OR 5-YEAR COLLEGE, OR BACHELOR'S DEGREE", 
                                                        "(10) SOME GRADUATE SCHOOL", 
                                                        "(11) MASTER'S DEGREE", 
                                                        "(12) PH.D., ED.D., MD, DDS, LLB, LLD, JD, OR OTHER PROFESS'NL DEG"))

df$SMOKING_STATUS <- ifelse(df$B4H26 == "(2) NO", "Never", ifelse(df$B4H26A == "(1) YES", "Current", "Past"))

df$OPTIMISM <- df$B1SORIEN
df$AGE <- df$B1PAGE_M2.x
df$GENDER <- ifelse(df$B1PRSEX.x == "(1) MALE", 0, 1)
df$RACE <- ifelse(df$B1PF7A == "(1) WHITE", 0, 1)
df$EDUCATION <- ifelse(df$B1PB1 == "(1) LESS THAN A HIGH SCHOOL DEGREE", 1, 
                       ifelse(df$B1PB1 == "(2) HIGH SCHOOL DEGREE", 2, 
                       ifelse(df$B1PB1 == "(3) SOME COLLEGE", 3, 4)))
df$INCOME <- df$B1STINC1
df$INTERVAL <- df$B4ZB1SLG
df$CHROX <- ifelse(df$B1SCHROX == "(1) YES", 1, 0)
df$BPMEDS <- ifelse(df$B1PA24B == "(1) YES", 1, 0)
df$BMI <- df$B4PBMI
df$SMOKING <- ifelse(df$SMOKING_STATUS == "Current", 1, 
              ifelse(df$SMOKING_STATUS == "Past", 2, 3))
df$ALCOHOL <- df$B4H36
df$PRUDENT_DIET <- df$prudent_diet
df$EXERCISE <- ifelse(df$B4H25 == "(1) YES", 1, 0)
df$NEGAF <- df$B1SNEGAF

# calculate the correlation coefficient test values
covariates <- c("AGE", "GENDER", "RACE", "EDUCATION", "INCOME", "INTERVAL", "CHROX",
                "BPMEDS", "BMI", "SMOKING", "ALCOHOL", "PRUDENT_DIET", "EXERCISE", "NEGAF")
table2 <- setNames(data.frame(matrix(ncol = 3, nrow = 1), stringsAsFactors = F), c("Characteristic", "r", "p"))

for (var in covariates) {
 cor <- cor.test(df[,var], df$B1SORIEN)
  r <- cor$estimate
  p <- cor$p.value 
  table2 <- rbind(table2, c(var, r, p))
}
```

```{r}
table2[2:15,]
```
As expected, most of our values differ slightly from the actual paper given the different sample sizes, but for the most part, all of the differences are very small. Almost all of our correlation coefficients and p-values are within $\pm 0.03$ and $\pm 0.10$ of the reported values, respectively. The only difference is in the chronic conditions values. We previously noted that our chronic condition distribution values were much different in Table 1 as well. In the original paper, the chronic conditions value was actually the least significant characteristic, whereas we find a p-value that is $<0.0001$. This again just points to the fact that we are likely using a different column for defining chronic conditions than the original authors intended. 


## Table 3

Before reproducing Tables 3, it's important to mimic the author's procedure for adjusting cholesterol levels. Specifically, the authors mention that "in accordance with previous research, the lipid levels of those participants who were taking cholesterol medicine (n = 284) were corrected for the typical effect of such treatment. That is, we increased the levels of total cholesterol by 20%, LDL cholesterol by 35%, and triglycerides by 15% and decreased the levels of HDL cholesterol by 5%. Because the distribution of triglyceride scores was skewed and kurtotic, the triglyceride scores were log transformed." However, the `B1SA12C` variable in the MIDUS II dataset, which defines "taking cholesterol medicine", contains a lot of missing values and we find only $n = 221$ participants in our dataset who are taking this type of medication. We will adjust the values for these patients regardless, but it may affect our results. 

```{r}
# Adjust cholesterol levels of those taking medication

df$CHOL_RX <- ifelse(df$B1SA12C == "(1) YES", 1, 0)
df[is.na(df$CHOL_RX), "CHOL_RX"] <- 0
df$TOTAL_CHOL <- df$B4BCHOL
df$LDL <- df$B4BLDL
df$HDL <- df$B4BHDL
df$TRIGL <- df$B4BTRIGL
df$CHOL_ADJ <- df$TOTAL_CHOL
df[df$CHOL_RX == 1, ]$CHOL_ADJ <- round(df[df$CHOL_RX == 1, "TOTAL_CHOL"] + 
                                       (df[df$CHOL_RX == 1, "TOTAL_CHOL"] * 0.2)) 
df$LDL_ADJ <- df$LDL
df[df$CHOL_RX == 1, ]$LDL_ADJ <- round(df[df$CHOL_RX == 1, "LDL"] + 
                                      (df[df$CHOL_RX == 1, "LDL"] * 0.35)) 
df$HDL_ADJ <- df$HDL
df[df$CHOL_RX == 1, ]$HDL_ADJ <- round(df[df$CHOL_RX == 1, "HDL"] - 
                                      (df[df$CHOL_RX == 1, "HDL"] * 0.05)) 
df$TRIGL_ADJ <- df$TRIGL
df[df$CHOL_RX == 1, ]$TRIGL_ADJ <- round(df[df$CHOL_RX == 1, "TRIGL"] + 
                                        (df[df$CHOL_RX == 1, "TRIGL"] * 0.15)) 
# Perform log transformation of TRIGL scores
df$LOG_TRIGL <- log10(df$TRIGL)
df$LOG_TRIGL_ADJ <- log10(df$TRIGL_ADJ)
```

Now that we have adjusted the cholesterol values as stated in the paper, we can fit the linear models to attempt to reproduce Table 3 from the paper. Note that Table 3 reports unstandardized parameter estimates and 95% confidence intervals (CIs) for the association between one SD increase in optimism and lipid levels. We therefore will run a `lm()` model for each lipid value using optimism and the appropriate covariates (depending on Model 1 or Model 2 as described in Table 3 from the paper) to obtain the regression coefficients. However, we will need to multiply the coefficient values by the standard deviation of optimism values to get the same type of table. 

```{r}
# Obtain standard deviation of optimism
s <- sd(df$OPTIMISM)

# Models for total cholesterol
lm1 <- lm(CHOL_ADJ ~ OPTIMISM + AGE + GENDER + RACE + EDUCATION + INCOME + INTERVAL, data=df)
lm1.confInt <- confint.lm(lm1)
lm1$coefficients[2] * s
lm1.confInt[2,1] * s
lm1.confInt[2,2] * s

lm2 <- lm(CHOL_ADJ ~ OPTIMISM + AGE + GENDER + RACE + EDUCATION + INCOME + INTERVAL + CHROX + BPMEDS, data=df)
lm2.confInt <- confint.lm(lm2)
lm2$coefficients[2] * s
lm2.confInt[2,1] * s
lm2.confInt[2,2] * s

# Models for HDL
lm1 <- lm(HDL_ADJ ~ OPTIMISM + AGE + GENDER + RACE + EDUCATION + INCOME + INTERVAL, data=df)
lm1.confInt <- confint.lm(lm1)
lm1$coefficients[2] * s
lm1.confInt[2,1] * s
lm1.confInt[2,2] * s
lm2 <- lm(HDL_ADJ ~ OPTIMISM + AGE + GENDER + RACE + EDUCATION + INCOME + INTERVAL + CHROX + BPMEDS, data=df)
lm2.confInt <- confint.lm(lm2)
lm2$coefficients[2] * s
lm2.confInt[2,1] * s
lm2.confInt[2,2] * s

# Models for LDL
lm1 <- lm(LDL_ADJ ~ OPTIMISM + AGE + GENDER + RACE + EDUCATION + INCOME + INTERVAL, data=df)
lm1.confInt <- confint.lm(lm1)
lm1$coefficients[2] * s
lm1.confInt[2,1] * s
lm1.confInt[2,2] * s
lm2 <- lm(LDL_ADJ ~ OPTIMISM + AGE + GENDER + RACE + EDUCATION + INCOME + INTERVAL + CHROX + BPMEDS, data=df)
lm2.confInt <- confint.lm(lm2)
lm2$coefficients[2] * s
lm2.confInt[2,1] * s
lm2.confInt[2,2] * s

# Models for triglycerides
lm1 <- lm(LOG_TRIGL_ADJ ~ OPTIMISM + AGE + GENDER + RACE + EDUCATION + INCOME + INTERVAL, data=df)
lm1.confInt <- confint.lm(lm1)
lm1$coefficients[2] * s
lm1.confInt[2,1] * s
lm1.confInt[2,2] * s
lm2 <- lm(LOG_TRIGL_ADJ ~ OPTIMISM + AGE + GENDER + RACE + EDUCATION + INCOME + INTERVAL + CHROX + BPMEDS, data=df)
lm2.confInt <- confint.lm(lm2)
lm2$coefficients[2] * s
lm2.confInt[2,1] * s
lm2.confInt[2,2] * s
```

Once again, we observe slightly different values than those reported in the authors' Table 3, but we are still very close that the differences can be attributed to the difference in our sample size and software. As the authors observed, we find that optimism was not associated with LDL cholesterol and total cholesterol levels but was associated with HDL cholesterol and triglycerides in the expected directions. For each SD increase in optimism, the HDL cholesterol levels were >1.5 mg/dl greater. For each SD increase in optimism, the triglyceride levels were ~2% lower. These are consistent with the author's findings. 

## Critique
1. Is the data publicly available?
*
2. Is the data easy/intuitive to access?
*
3. Is there a codebook and/or instructions about how the data and documentation is organized?
*
4. Are the file names intuitive?
*
5. Are the variable names intuitive?
*
6. Is the software used for analysis publicly available?
*
7. If the software is available, is it well commented?
*
8. Is there a toy example provided?
*
9. Are you able to reproduce the figures, tables and results presented in the paper?
*
10. Was there anything you think should have been made clearer, or explained in a different way?
*
11. Did you find any faults in the methods used in this paper? Would you have used more or different methods?
*





